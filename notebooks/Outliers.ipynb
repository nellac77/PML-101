{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/logo.png'>\n",
    "<img src='img/title.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks discusses several different techniques for identification of statistical outliers, including elliptic envelopes, PCA, kernel density estimatation, and isolation forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Outlier detection](#Outlier-detection)\n",
    "\t* [Example data: German Credit Card Fraud](#Example-data:-German-Credit-Card-Fraud)\n",
    "\t\t* [Dummies](#Dummies)\n",
    "\t* [Elliptic Envelope](#Elliptic-Envelope)\n",
    "\t* [PCA](#PCA)\n",
    "\t* [Kernel Density Estimation (KDE)](#Kernel-Density-Estimation-%28KDE%29)\n",
    "\t* [Isolation Forest](#Isolation-Forest)\n",
    "\t* [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix working directory\n",
    "%cd notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "hv.extension('bokeh')\n",
    "\n",
    "import src.mglearn as mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data: German Credit Card Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we encode the categoricals to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/german_cc_fraud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with many Scikit-learn models we need to transform categorical features to True/False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies = pd.get_dummies(data.drop(\"class\", axis=1), drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dummies.columns  # expansion in number of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dummies.values.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elliptic Envelope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Envelope outlier detection on scaled and PCA transformed input `X` data.\n",
    "\n",
    "`EllipticEnvelope` can detect outliers in Gaussian distributed data.  Note there is important cautionary [advice in the docs](http://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html) that:\n",
    "\n",
    "```text\n",
    "Outlier detection from covariance estimation may break or not perform well in high-dimensional settings. In particular, one will always take care to work with \n",
    "\n",
    "n_samples > n_features ** 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.covariance import EllipticEnvelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "pca = PCA(n_components=.8)\n",
    "X_preprocessed = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = EllipticEnvelope(contamination=.3).fit(X_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(data['class'] == \"good\", ee.predict(X_preprocessed) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(data['class'] == \"good\", ee.decision_function(X_preprocessed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the explained variance ratio, which shows the relative variance explained by each of the extracted principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = PCA().fit(X_scaled)\n",
    "\n",
    "hv.Curve(pca_full.explained_variance_ratio_, 'feature', 'component').options(padding=0.05, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(data['class'] == \"good\", pca.score_samples(X_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation (KDE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [sklearn docs on KDE](http://scikit-learn.org/stable/modules/density.html) go through an interesting an example demonstrating how binning data into fixed bins can lead to misleading histogram figures with appearances stronly related to the shifting of bins.\n",
    "\n",
    "Kernel density methods are often used for histogram smoothing.  The kernel functions each take a `bandwidth` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde = KernelDensity(bandwidth=5).fit(X_scaled)\n",
    "\n",
    "hist = np.histogram(kde.score_samples(X_scaled), bins=100, density=True)\n",
    "hv.Histogram(hist).options(width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(data['class'] == \"good\", kde.score_samples(X_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation forest is [recursive splitting algorithm](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html) for finding outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "iso = IsolationForest(contamination=.3, behaviour='new').fit(data_dummies.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "confusion_matrix(data['class'] == \"good\", iso.predict(data_dummies.values) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(data['class'] == \"good\", iso.decision_function(data_dummies.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we reviewed the following topics in preparation for more advanced topics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Elliptic Envelope](#Elliptic-Envelope)\n",
    "* [PCA](#PCA)\n",
    "* [Kernel Density Estimation (KDE)](#Kernel-Density-Estimation-%28KDE%29)\n",
    "* [Isolation Forest](#Isolation-Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/copyright.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [module-machine-learning]",
   "language": "python",
   "name": "anaconda-project-module-machine-learning-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
